{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import seed\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (40%) Correctly implement the ID3 decision tree algorithm, including the ability to handle unknown attributes (You do not need to handle real valued attributes).  \n",
    "### Code Requirements/Notes:\n",
    "- Use standard information gain as your basic attribute evaluation metric.  (Note that normal ID3 would usually augment information gain with gain ratio or some other mechanism to penalize statistically insignificant attribute splits. Otherwise, even with approaches like pruning below, the SSE type of overfit could still hurt us.) \n",
    "- You are welcome to create other classes and/or functions in addition to the ones provided below. (e.g. If you build out a tree structure, you might create a node class).\n",
    "- It is a good idea to use a simple data set (like the lenses data or the pizza homework), which you can check by hand, to test your algorithm to make sure that it is working correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTClassifier(BaseEstimator,ClassifierMixin):\n",
    "\n",
    "    def __init__(self,counts=None):\n",
    "        \"\"\" Initialize class with chosen hyperparameters.\n",
    "        Args:\n",
    "        Optional Args (Args we think will make your life easier):\n",
    "            counts: A list of Ints that tell you how many types of each feature there are\n",
    "        Example:\n",
    "            DT  = DTClassifier()\n",
    "            or\n",
    "            DT = DTClassifier(count = [2,3,2,2])\n",
    "            Dataset = \n",
    "            [[0,1,0,0],\n",
    "            [1,2,1,1],\n",
    "            [0,1,1,0],\n",
    "            [1,2,0,1],\n",
    "            [0,0,1,1]]\n",
    "\n",
    "        \"\"\"\n",
    "        self.ig_splits = []\n",
    "        \n",
    "\n",
    "    def fit(self, x, y, Print=False):\n",
    "        \"\"\" Fit the data; Make the Decision tree\n",
    "\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "            y (array-like): A 1D numpy array with the training targets\n",
    "\n",
    "        Returns:\n",
    "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
    "\n",
    "        \"\"\"\n",
    "        data = x.copy()\n",
    "        data[y.name] = y\n",
    "        self.tree = self.convert(self.decision_tree(data, data, x.columns, y.name, Print))\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict all classes for a dataset X\n",
    "\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "\n",
    "        Returns:\n",
    "            array, shape (n_samples,)\n",
    "                Predicted target values per element in X.\n",
    "        \"\"\"\n",
    "        \n",
    "        # convert input data into a dictionary of samples\n",
    "        samples = self.convert(X.to_dict(orient='records'))\n",
    "        \n",
    "        predictions = []\n",
    "        # make a prediction for every sample\n",
    "        for sample in samples:\n",
    "          predictions.append(self.make_prediction(sample, self.tree, 1.0))\n",
    "        return predictions\n",
    "\n",
    "    def entropy(self, attribute_column):\n",
    "        # find unique values and their frequency counts for the given attribute\n",
    "        values, counts = np.unique(attribute_column, return_counts=True)\n",
    "\n",
    "        # calculate entropy for each unique value\n",
    "        entropy_list = []\n",
    "\n",
    "        for i in range(len(values)):\n",
    "          probability = counts[i]/np.sum(counts)\n",
    "          entropy_list.append(-probability*np.log2(probability))\n",
    "\n",
    "        # calculate sum of individual entropy values\n",
    "        total_entropy = np.sum(entropy_list)\n",
    "\n",
    "        return total_entropy\n",
    "    \n",
    "    def information_gain(self, data, feature_attribute_name, target_attribute_name):\n",
    "        # find total entropy of given subset\n",
    "        total_entropy = self.entropy(data[target_attribute_name])\n",
    "\n",
    "        # find unique values and their frequency counts for the attribute to be split\n",
    "        values, counts = np.unique(data[feature_attribute_name], return_counts=True)\n",
    "\n",
    "        # calculate weighted entropy of subset\n",
    "        weighted_entropy_list = []\n",
    "\n",
    "        for i in range(len(values)):\n",
    "          subset_probability = counts[i]/np.sum(counts)\n",
    "          subset_entropy = self.entropy(data.where(data[feature_attribute_name]==values[i]).dropna()[target_attribute_name])\n",
    "          weighted_entropy_list.append(subset_probability*subset_entropy)\n",
    "\n",
    "        total_weighted_entropy = np.sum(weighted_entropy_list)\n",
    "\n",
    "        # calculate information gain\n",
    "        information_gain = total_entropy - total_weighted_entropy\n",
    "\n",
    "        return information_gain\n",
    "    \n",
    "    def decision_tree(self, data, orginal_data, feature_attribute_names, target_attribute_name,\n",
    "                      Print=False, depth=\"\", parent_node_class=None):\n",
    "        # base cases:\n",
    "        # if data is pure, return the majority class of subset\n",
    "        unique_classes = np.unique(data[target_attribute_name])\n",
    "        if len(unique_classes) <= 1:\n",
    "            if(Print):\n",
    "                print(f\"{depth}prediction = {unique_classes[0].decode()}\")\n",
    "            return unique_classes[0]\n",
    "        # if subset is empty, ie. no samples, return majority class of original data\n",
    "        elif len(data) == 0:\n",
    "          majority_class_index = np.argmax(np.unique(original_data[target_attribute_name], return_counts=True)[1])\n",
    "          return np.unique(original_data[target_attribute_name])[majority_class_index]\n",
    "        # if data set contains no features to train with, return parent node class\n",
    "        elif len(feature_attribute_names) == 0:\n",
    "          return parent_node_class\n",
    "        # if none of the above are true, construct a branch:\n",
    "        else:\n",
    "          # determine parent node class of current branch\n",
    "          majority_class_index = np.argmax(np.unique(data[target_attribute_name], return_counts=True)[1])\n",
    "          parent_node_class = unique_classes[majority_class_index]\n",
    "\n",
    "          # determine information gain values for each feature\n",
    "          # choose feature which best splits the data, ie. highest value\n",
    "          ig_values = [self.information_gain(data, feature, target_attribute_name) for feature in feature_attribute_names]\n",
    "          best_feature_index = np.argmax(ig_values)\n",
    "          self.ig_splits.append(ig_values[best_feature_index])\n",
    "          best_feature = feature_attribute_names[best_feature_index]\n",
    "            \n",
    "          # create tree structure, empty at first\n",
    "          tree = {best_feature: {}}\n",
    "\n",
    "          # remove best feature from available features, it will become the parent node\n",
    "          feature_attribute_names = [i for i in feature_attribute_names if i != best_feature]\n",
    "\n",
    "          # create nodes under parent node\n",
    "          parent_attribute_values = np.unique(data[best_feature])\n",
    "          for value in parent_attribute_values:\n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "            if Print:\n",
    "                print(f\"{depth}{best_feature} = {value.decode()}\")\n",
    "            # call the algorithm recursively\n",
    "            subtree = self.decision_tree(sub_data, orginal_data, feature_attribute_names,\n",
    "                                         target_attribute_name, Print, depth+'    ', parent_node_class)\n",
    "\n",
    "            # add subtree to original tree\n",
    "            tree[best_feature][value] = subtree\n",
    "\n",
    "          return tree\n",
    "    \n",
    "    def make_prediction(self, sample, tree, default=1):\n",
    "        # map sample data to tree\n",
    "        for attribute in list(sample.keys()):\n",
    "          # check if feature exists in tree\n",
    "          if attribute in list(tree.keys()):\n",
    "            try:\n",
    "                result = tree[attribute][sample[attribute]]\n",
    "            except:\n",
    "                return default\n",
    "\n",
    "            result = tree[attribute][sample[attribute]]\n",
    "\n",
    "            # if more attributes exist within result, recursively find best result\n",
    "            if isinstance(result, dict):\n",
    "                return self.make_prediction(sample, result)\n",
    "            else:\n",
    "                return result\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\" Return accuracy(Classification Acc) of model on a given dataset. Must implement own score function.\n",
    "\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with data, excluding targets\n",
    "            y (array-like): A 1D numpy array of the targets \n",
    "        \"\"\"\n",
    "        pred = self.predict(X)\n",
    "        y = np.array(self.convert(list(y)))\n",
    "        return np.mean(pred == y)\n",
    "    \n",
    "    def convert(self, data):\n",
    "        if isinstance(data, bytes):  return data.decode()\n",
    "        if isinstance(data, dict):   return dict(map(self.convert, data.items()))\n",
    "        if isinstance(data, tuple):  return tuple(map(self.convert, data))\n",
    "        if isinstance(data, list):   return list(map(self.convert, data))\n",
    "        return data\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Debug \n",
    "\n",
    "Debug your model by training on the lenses dataset: [Debug Dataset](https://github.com/cs472ta/CS472/blob/master/datasets/lenses.arff)\n",
    "\n",
    "Test your model on the lenses test set: [Debug Test Dataset](https://github.com/cs472ta/CS472/blob/master/datasets/lenses_test.arff)\n",
    "\n",
    "Parameters:\n",
    "validation_size = 0.0\n",
    "\n",
    "---\n",
    "\n",
    "Expected Results: Accuracy = [0.33]\n",
    "\n",
    "Predictions should match this file: [Lenses Predictions](https://github.com/cs472ta/CS472/blob/master/debug_solutions/pred_lenses.csv)\n",
    "\n",
    "<!-- You should be able to get about 68% (61%-82%) predictive accuracy on the lenses data -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tear_prod_rate = normal\n",
      "    astigmatism = no\n",
      "        age = pre_presbyopic\n",
      "            prediction = soft\n",
      "        age = presbyopic\n",
      "            spectacle_prescrip = hypermetrope\n",
      "                prediction = soft\n",
      "            spectacle_prescrip = myope\n",
      "                prediction = none\n",
      "        age = young\n",
      "            prediction = soft\n",
      "    astigmatism = yes\n",
      "        spectacle_prescrip = hypermetrope\n",
      "            age = pre_presbyopic\n",
      "                prediction = none\n",
      "            age = presbyopic\n",
      "                prediction = none\n",
      "            age = young\n",
      "                prediction = hard\n",
      "        spectacle_prescrip = myope\n",
      "            prediction = hard\n",
      "tear_prod_rate = reduced\n",
      "    prediction = none\n",
      "[0.5487949406953985, 0.7704260414863778, 0.3166890883150208, 1.0, 0.4591479170272448, 0.9182958340544896]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load debug training data\n",
    "data = pd.DataFrame(arff.loadarff('datasets/lenses.arff')[0], dtype=float)\n",
    "\n",
    "# Train Decision Tree\n",
    "x_train = data.drop(columns=\"contact_lenses\")\n",
    "y_train = data[\"contact_lenses\"]\n",
    "dt = DTClassifier()\n",
    "dt.fit(x_train, y_train, True)\n",
    "print(dt.ig_splits)\n",
    "\n",
    "# Load debug test data\n",
    "data = pd.DataFrame(arff.loadarff('datasets/lenses_test.arff')[0], dtype=float)\n",
    "\n",
    "# Predict and compute model accuracy\n",
    "x_test = data.drop(columns=\"contact_lenses\")\n",
    "y_test = data[\"contact_lenses\"]\n",
    "dt.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional/Additional Debugging Dataset - Pizza Homework\n",
    "# pizza_dataset = np.array([[1,2,0],[0,0,0],[0,1,1],[1,1,1],[1,0,0],[1,0,1],[0,2,1],[1,0,0],[0,2,0]])\n",
    "# pizza_labels = np.array([2,0,1,2,1,2,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Evaluation\n",
    "\n",
    "We will evaluate your model based on its performance on the zoo dataset. \n",
    "\n",
    "Train your model using this dataset: [Evaluation Train Dataset](https://github.com/cs472ta/CS472/blob/master/datasets/zoo.arff)\n",
    "\n",
    "Test your model on this dataset: [Evaluation Test Dataset](https://github.com/cs472ta/CS472/blob/master/datasets/zoo_test.arff)\n",
    "\n",
    "Parameters: \n",
    "validation_size = 0.0\n",
    "\n",
    "---\n",
    "Save predictions as a .csv and which you'll submit together with this notebook on LearningSuite **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "legs = 0\n",
      "    fins = F\n",
      "        toothed = F\n",
      "            prediction = c7\n",
      "        toothed = T\n",
      "            prediction = c3\n",
      "    fins = T\n",
      "        eggs = F\n",
      "            prediction = cT\n",
      "        eggs = T\n",
      "            prediction = c4\n",
      "legs = 2\n",
      "    hair = F\n",
      "        prediction = c2\n",
      "    hair = T\n",
      "        prediction = cT\n",
      "legs = 4\n",
      "    hair = F\n",
      "        predator = F\n",
      "            prediction = c3\n",
      "        predator = T\n",
      "            toothed = F\n",
      "                prediction = c7\n",
      "            toothed = T\n",
      "                prediction = c5\n",
      "    hair = T\n",
      "        prediction = cT\n",
      "legs = 5\n",
      "    prediction = c7\n",
      "legs = 6\n",
      "    predator = F\n",
      "        prediction = c6\n",
      "    predator = T\n",
      "        prediction = c7\n",
      "legs = 8\n",
      "    prediction = c7\n",
      "[1.3630469031539394, 0.8865408928220899, 0.9852281360342515, 0.6962122601251458, 0.8256265261578954, 0.6892019851173654, 0.8631205685666308, 0.7219280948873623, 0.7219280948873623]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.147"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load evaluation training data\n",
    "data = pd.DataFrame(arff.loadarff('datasets/zoo.arff')[0])\n",
    "\n",
    "# Train Decision Tree\n",
    "x_train = data.drop(columns=\"type\")\n",
    "y_train = data[\"type\"]\n",
    "dt = DTClassifier()\n",
    "dt.fit(x_train, y_train, True)\n",
    "print(dt.ig_splits)\n",
    "\n",
    "# Load evaluation test data\n",
    "data = pd.DataFrame(arff.loadarff('datasets/zoo_test.arff')[0])\n",
    "\n",
    "# Predict and compute model accuracy\n",
    "x_test = data.drop(columns=\"type\")\n",
    "y_test = data[\"type\"]\n",
    "dt.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (20%) You will use your ID3 algorithm to induce decision trees for the cars dataset and the voting dataset.  Do not use a stopping criteria, but induce the tree as far as it can go (until classes are pure or there are no more data or attributes to split on).  \n",
    "- Implement and use 10-fold CV on each data set to predict how well the models will do on novel data.  \n",
    "- For each dataset, report the training and test classification accuracy for each fold and the average test accuracy. \n",
    "- Summarize these results, and discuss what you observed. Note that with a full tree you will often get 100% accuracy on the training set. Why would you and in what cases would you not?  \n",
    "- As a rough sanity check, typical decision tree accuracies for these data sets are: Cars: .90-.95, Vote: .92-.95."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Implement 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_i_of_k(dataset, i, k):\n",
    "    n = len(dataset)\n",
    "    return dataset[n*(i-1)//k:n*i//k]\n",
    "\n",
    "def k_fold_cross_validate(data, output_class, folds=3):\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    data_set = []\n",
    "    scores = []\n",
    "    j = 0\n",
    "    for i in range(1, folds+1):\n",
    "        data_set.append(fold_i_of_k(data, i, folds))\n",
    "    for i in range(folds):\n",
    "        dfs_1 = data_set[0:i]\n",
    "        dfs_2 = data_set[i+1:len(data_set)+1]\n",
    "        df = dfs_1 + dfs_2\n",
    "        df = pd.concat(df)\n",
    "        x_train = df.drop(columns=output_class)\n",
    "        y_train = df[output_class]\n",
    "        x_test = data_set[i].drop(columns=output_class)\n",
    "        y_test = data_set[i][output_class]\n",
    "        dt = DTClassifier()\n",
    "        dt.fit(x_train, y_train)\n",
    "        score = dt.score(x_test, y_test)\n",
    "        print(score)\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.2 Cars Dataset\n",
    "- Use this [Cars Dataset](https://github.com/cs472ta/CS472/blob/master/datasets/cars.arff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8953488372093024\n",
      "0.9190751445086706\n",
      "0.884393063583815\n",
      "0.861271676300578\n",
      "0.930635838150289\n",
      "0.9069767441860465\n",
      "0.8901734104046243\n",
      "0.8728323699421965\n",
      "0.884393063583815\n",
      "0.9190751445086706\n",
      "average accuracy: 0.8964175292378009\n"
     ]
    }
   ],
   "source": [
    "# Use 10-fold CV on Cars Dataset\n",
    "data = arff.loadarff('datasets/cars.arff')[0]\n",
    "df =  pd.DataFrame(data)\n",
    "scores = k_fold_cross_validate(df, \"class\", 10)\n",
    "print(f\"average accuracy: {np.mean(np.mean(scores))}\")\n",
    "cdt = dt.tree\n",
    "# Report Average Test Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Voting Dataset\n",
    "- Use this [Voting Dataset with missing values](https://github.com/cs472ta/CS472/blob/master/datasets/voting_with_missing.arff)\n",
    "- Note that you will need to support unknown attributes in the voting data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9302325581395349\n",
      "0.9772727272727273\n",
      "1.0\n",
      "0.9545454545454546\n",
      "0.9534883720930233\n",
      "0.9318181818181818\n",
      "0.9534883720930233\n",
      "0.9318181818181818\n",
      "0.8604651162790697\n",
      "0.9318181818181818\n",
      "average accuracy: 0.9424947145877379\n"
     ]
    }
   ],
   "source": [
    "# Used 10-fold CV on Voting Dataset\n",
    "data = arff.loadarff('datasets/voting_with_missing.arff')[0]\n",
    "df =  pd.DataFrame(data)\n",
    "df = df.replace(\"?\", \"unknown\")\n",
    "scores = k_fold_cross_validate(df, \"Class\", 10)\n",
    "print(f\"average accuracy: {np.mean(np.mean(scores))}\")\n",
    "# Report Training and Test Classification Accuracies\n",
    "# Report Average Test Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. (10%) For each of the two problems above, summarize in English what the decision tree has learned (i.e. look at the induced tree and describe what rules it has discovered to try to solve each task). \n",
    "- If the tree is very large you can just discuss a few of the more shallow attributes combinations and the most important decisions made high in the tree.\n",
    "- To visualize your trees, you could use something like sklearn's export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Cars Decision Tree Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss what the decision tree induced on the cars dataset has learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'safety' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-242-4ba3a0e7b9bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msafety\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuying\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'safety' is not defined"
     ]
    }
   ],
   "source": [
    "safety, persons, buying, maint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Voting Decision Tree Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss what the decision tree induced on the voting dataset has learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physician-fee-freeze = ?\n",
    "    education-spending = ?\n",
    "physician-fee-freeze = n\n",
    "    adoption-of-the-budget-resolution = ?\n",
    "physician-fee-freeze = y\n",
    "    synfuels-corporation-cutback = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  (5%) How did you handle unknown attributes in the voting problem? Why did you choose this approach? (Do not use the approach of just throwing out data with unknown attributes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I made it a thrid option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 (10%) Use SciKit Learn's decision tree on the cars and voting datasets and compare your results. Try some of the approaches available to avoid overfit and report if that does better on a test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 SK Learn on Cars Dataset\n",
    "- Use this [Cars Dataset](https://github.com/cs472ta/CS472/blob/master/datasets/cars.arff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'vhigh'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-272-a6f25b2b0c45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Explore methods to avoid overfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \"\"\"\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    891\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             X, y = self._validate_data(X, y,\n\u001b[0m\u001b[1;32m    157\u001b[0m                                        validate_separately=(check_X_params,\n\u001b[1;32m    158\u001b[0m                                                             check_y_params))\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    427\u001b[0m                 \u001b[0;31m# :(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'vhigh'"
     ]
    }
   ],
   "source": [
    "# Use SK Learn's Decision Tree to learn the cars dataset\n",
    "def convert( data):\n",
    "    if isinstance(data, bytes):  return data.decode()\n",
    "    if isinstance(data, dict):   return dict(map(convert, data.items()))\n",
    "    if isinstance(data, tuple):  return tuple(map(convert, data))\n",
    "    if isinstance(data, list):   return list(map(convert, data))\n",
    "    return data\n",
    "data = arff.loadarff('datasets/cars.arff')[0]\n",
    "data = convert(data)\n",
    "df =  pd.DataFrame(data, dtype=float)\n",
    "\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "X = df.drop(columns=\"class\").values\n",
    "y = df[\"class\"].values\n",
    "X = np.array(convert(X.tolist()))\n",
    "y = np.array(convert(y.tolist()))\n",
    "\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "# Explore methods to avoid overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss results & compare to your method's results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 SK Learn on Voting Dataset\n",
    "- Use this [Voting Dataset with missing values](https://github.com/cs472ta/CS472/blob/master/datasets/voting_with_missing.arff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SK Learn's Decision Tree to learn the voting dataset\n",
    "\n",
    "# Explore methods to avoid overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss results & compare to your method's results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 (10%) Choose a data set of your choice (not already used in this or previous labs) and use the SK decision tree to learn it. Experinent with different hyper-parameters to try to get the best results possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_iris' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-273-033e0a8fa881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_iris' is not defined"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "X_train, X_test, y_train, y_test = tts(X,y)\n",
    "\n",
    "depths = [1, 3, 4, 5, 6,7, 8, 9, 10, 11, 12]\n",
    "max_feats = [2,'log2','sqrt','auto']\n",
    "crit = ['gini', 'entropy']\n",
    "scores = np.zeros((5,4,2))\n",
    "maximum, argm = 0, []\n",
    "for i,j,k in product(range(5),range(4),range(2)):\n",
    "    d,m,c = depths[i], max_feats[j], crit[k]\n",
    "    t = tree.DecisionTreeClassifier(criterion=c, max_depth=d, max_features=m)\n",
    "    t.fit(X_train,y_train)\n",
    "    new_score = t.score(X_test,y_test)\n",
    "    if new_score > maximum:\n",
    "        argm = [i,j,k]\n",
    "        maximum = new_score\n",
    "    scores[i][j][k] = new_score\n",
    "\n",
    "print(f'Best score: {round(maximum, 5)*100} at depth: {depths[argm[0]]}, max_features: {max_feats[argm[1]]}, and criterion: {crit[argm[2]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. (5%) Visualize your decision tree for your chosen data set (using export_graphviz or another tool) and discuss what you find. If your tree is too deep to reasonably fit on one page, show only the first several levels (e.g. top 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include decision tree visualization here\n",
    "t = tree.DecisionTreeClassifier(max_depth=depths[argm[0]],\n",
    "                                max_features=max_feats[argm[1]],\n",
    "                                criterion=crit[argm[2]])\n",
    "t.fit(X_train, y_train)\n",
    "ofile = tree.export_graphviz(t)\n",
    "plt.figure(figsize=(20,20))\n",
    "text = tree.plot_tree(t)\n",
    "# Discuss what the model has learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. (optional 5% extra credit) Implement reduced error pruning to help avoid overfitting.  \n",
    "- You will need to take a validation set out of your training data to do this, while still having a test set to test your final accuracy. \n",
    "- Create a table comparing the original trees created for your ID3 version with the cars and voting data sets with no overfit avoidance in part 2 and the new trees you create with pruning. \n",
    "- This table should compare:\n",
    "    - a) The # of nodes (including leaf nodes) and tree depth of the final decision trees \n",
    "    - b) The generalization (test set) accuracy. (For the unpruned 10-fold CV models, just use their average values in the table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
